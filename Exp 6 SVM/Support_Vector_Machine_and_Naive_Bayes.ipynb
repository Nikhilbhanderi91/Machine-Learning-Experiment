{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Support Vector Machine"
      ],
      "metadata": {
        "id": "lcMYwnOUp_sZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "D2ohfNbblPRr",
        "outputId": "a4d153c1-ddbe-4d43-942a-276e9760a588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original shape: (150, 4), classes: [0 1 2]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "\n",
        "data = load_iris()\n",
        "\n",
        "X_full = data.data\n",
        "y = data.target\n",
        "print(f\"original shape: {X_full.shape}, classes: {np.unique(y)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_2d = pca.fit_transform(StandardScaler().fit_transform(X_full))\n",
        "print(\"Explained variance ratio by 2 PCA components:\", pca.explained_variance_ratio_)\n",
        "\n",
        "# Standardize the 2D projected features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X_2d)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.25, random_state=1, stratify=y)\n",
        "\n",
        "\n",
        "def plot_decision_regions(clf, X_train, y_train, title, is_precomputed=False, gamma_pre=None):\n",
        "    # grid\n",
        "    x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n",
        "    y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 400),\n",
        "                         np.linspace(y_min, y_max, 400))\n",
        "    grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "\n",
        "    if is_precomputed:\n",
        "        if gamma_pre is None:\n",
        "            raise ValueError(\"gamma_pre must be provided for precomputed kernel plotting\")\n",
        "        K_grid = rbf_kernel(grid, X_train, gamma=gamma_pre)  # shape: (n_grid, n_train)\n",
        "        Z = clf.predict(K_grid)\n",
        "    else:\n",
        "        Z = clf.predict(grid)\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    plt.figure(figsize=(7,6))\n",
        "    plt.contourf(xx, yy, Z, alpha=0.3)          # predicted class regions\n",
        "    plt.contour(xx, yy, Z, levels=np.unique(Z), linewidths=0.3, alpha=0.7)\n",
        "    plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolor='k', s=30)\n",
        "    # support vectors â€” for precomputed kernel use indices in clf.support_\n",
        "    sv = clf.support_vectors_ if not is_precomputed else X_train[clf.support_]\n",
        "    plt.scatter(sv[:, 0], sv[:, 1], facecolors='none', edgecolors='k',\n",
        "                s=80, linewidths=1.2, label='Support Vectors')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('PCA component 1 (standardized)')\n",
        "    plt.ylabel('PCA component 2 (standardized)')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "AlDUpqBMldT4",
        "outputId": "f0bf96d5-5520-4c99-a890-e596165dd3a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explained variance ratio by 2 PCA components: [0.72962445 0.22850762]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "results = []\n",
        "\n",
        "for kernel in kernels:\n",
        "\n",
        "        if kernel == 'poly':\n",
        "            clf = SVC(kernel='poly', degree=3, gamma='scale', C=1.0, decision_function_shape='ovr')\n",
        "        else:\n",
        "            clf = SVC(kernel=kernel, gamma='scale', C=1.0, decision_function_shape='ovr')\n",
        "        clf.fit(X_train, y_train)\n",
        "        y_pred = clf.predict(X_test)\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        report = classification_report(y_test, y_pred, output_dict=True)\n",
        "        results.append({'kernel': kernel, 'accuracy': acc, 'report': report, 'clf': clf})\n",
        "        plot_decision_regions(clf, X_train, y_train, f\"SVC kernel='{kernel}'\", is_precomputed=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JFAiWLbPpIIp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary_rows = []\n",
        "for r in results:\n",
        "    k = r['kernel']\n",
        "    acc = r['accuracy']\n",
        "    macro_f1 = r['report'].get('macro avg', {}).get('f1-score', None)\n",
        "    summary_rows.append({'Kernel': k, 'Accuracy': round(acc,4),\n",
        "                         'Macro_F1': round(macro_f1,4) if macro_f1 is not None else None})\n",
        "\n",
        "summary_df = pd.DataFrame(summary_rows).sort_values('Accuracy', ascending=False).reset_index(drop=True)\n",
        "print(\"\\nSVC kernel comparison summary:\\n\")\n",
        "print(summary_df.to_string(index=False))\n",
        "# Optionally save\n",
        "summary_df.to_csv(\"svm_kernel_sklearn_dataset_summary.csv\", index=False)\n",
        "print(\"\\nSaved summary to 'svm_kernel_sklearn_dataset_summary.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0dNLtI06pSq7",
        "outputId": "d00cefc1-4a19-4d28-cf2a-89e59547e382"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SVC kernel comparison summary:\n",
            "\n",
            " Kernel  Accuracy  Macro_F1\n",
            "   poly    0.8421    0.8424\n",
            "    rbf    0.8421    0.8462\n",
            " linear    0.8158    0.8202\n",
            "sigmoid    0.7368    0.7421\n",
            "\n",
            "Saved summary to 'svm_kernel_sklearn_dataset_summary.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PpHAFDgxpU4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Naive Bayes"
      ],
      "metadata": {
        "id": "KoiS9oNgqDcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score,\n",
        "    f1_score, confusion_matrix, classification_report\n",
        ")\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "models = {\n",
        "    \"GaussianNB\": GaussianNB(),\n",
        "    \"MultinomialNB\": MultinomialNB(),\n",
        "    \"BernoulliNB\": BernoulliNB()\n",
        "}\n"
      ],
      "metadata": {
        "id": "SFu9_wVNqZie"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, model in models.items():\n",
        "    print(f\"Model: {name}\")\n",
        "    print(\"==============================\")\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision (macro):\", precision_score(y_test, y_pred, average='macro'))\n",
        "    print(\"Recall (macro):\", recall_score(y_test, y_pred, average='macro'))\n",
        "    print(\"F1 Score (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
        "\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"\\nConfusion Matrix:\\n\", cm)\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=iris.target_names))\n",
        "\n",
        "    plt.figure(figsize=(5,4))\n",
        "    sns.heatmap(cm, annot=True, cmap=\"Blues\", fmt=\"d\",\n",
        "                xticklabels=iris.target_names,\n",
        "                yticklabels=iris.target_names)\n",
        "    plt.title(f\"Confusion Matrix - {name}\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "P_hso3bqrccv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create summary list\n",
        "summary = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    summary.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "        \"Precision (macro)\": precision_score(y_test, y_pred, average='macro'),\n",
        "        \"Recall (macro)\": recall_score(y_test, y_pred, average='macro'),\n",
        "        \"F1 Score (macro)\": f1_score(y_test, y_pred, average='macro')\n",
        "    })\n",
        "\n",
        "# Convert to DataFrame\n",
        "summary_df = pd.DataFrame(summary)\n",
        "\n",
        "# Print consolidated report\n",
        "print(\"   CONSOLIDATED REPORT\")\n",
        "print(summary_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2bccm3WSrkLE",
        "outputId": "7908a62e-e282-463c-daaf-14d01d023950"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   CONSOLIDATED REPORT\n",
            "           Model  Accuracy  Precision (macro)  Recall (macro)  \\\n",
            "0     GaussianNB  0.977778           0.976190        0.974359   \n",
            "1  MultinomialNB  0.955556           0.948718        0.948718   \n",
            "2    BernoulliNB  0.288889           0.096296        0.333333   \n",
            "\n",
            "   F1 Score (macro)  \n",
            "0          0.974321  \n",
            "1          0.948718  \n",
            "2          0.149425  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNbyHsvtrwcw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}